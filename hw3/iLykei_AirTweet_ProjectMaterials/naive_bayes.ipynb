{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from joblib import dump, load\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.metrics import log_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/henry/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/henry/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/henry/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>@SouthwestAir good thing we noticed because sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@united They let us know in advance of the reb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>@USAirways sucks. Delayed my mom's flight 2X, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>@united can you DM me? Been on hold with custo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>@AmericanAir THANK YOU FOR ALL THE HELP!  :P Y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13874</th>\n",
       "      <td>0</td>\n",
       "      <td>@JetBlue with 3 kids and 11 days 340 + doesn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13875</th>\n",
       "      <td>1</td>\n",
       "      <td>@AmericanAir LTALJX, from DCA to OMA this morn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13876</th>\n",
       "      <td>-1</td>\n",
       "      <td>@AmericanAir I can't work with them if the cal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13877</th>\n",
       "      <td>-1</td>\n",
       "      <td>@AmericanAir 2 months and still no exec platin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13878</th>\n",
       "      <td>-1</td>\n",
       "      <td>@united quality work going on here. http://t.c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13879 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sentiment                                              Tweet\n",
       "0             -1  @SouthwestAir good thing we noticed because sh...\n",
       "1              1  @united They let us know in advance of the reb...\n",
       "2             -1  @USAirways sucks. Delayed my mom's flight 2X, ...\n",
       "3             -1  @united can you DM me? Been on hold with custo...\n",
       "4              1  @AmericanAir THANK YOU FOR ALL THE HELP!  :P Y...\n",
       "...          ...                                                ...\n",
       "13874          0  @JetBlue with 3 kids and 11 days 340 + doesn't...\n",
       "13875          1  @AmericanAir LTALJX, from DCA to OMA this morn...\n",
       "13876         -1  @AmericanAir I can't work with them if the cal...\n",
       "13877         -1  @AmericanAir 2 months and still no exec platin...\n",
       "13878         -1  @united quality work going on here. http://t.c...\n",
       "\n",
       "[13879 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/air_tweet_train.csv', names=['Sentiment', 'Tweet'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specific lists of stopwords for this task\n",
    "aircompanies_accounts = ['VirginAmerica', 'United', 'SouthwestAir', 'JetBlue', \n",
    "                         'Delta', 'USAirways', 'AmericanAir']\n",
    "other_stopwords = ['fly', 'flying', 'flight', 'flights', 'plane']\n",
    "\n",
    "eng_stopwords = stopwords.words('english')\n",
    "eng_stopwords.extend([w.lower() for w in aircompanies_accounts])\n",
    "eng_stopwords.extend(other_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_tokenizer(tweet):\n",
    "    # Remove everything but letters:\n",
    "    tweet = re.sub(\"[^a-zA-Z]\", \" \", tweet)\n",
    "    # Make lower-case:\n",
    "    tweet = tweet.lower()\n",
    "    # Tokenize tweet:\n",
    "    tokens = nltk.word_tokenize(tweet)\n",
    "    # Remove stop-words:\n",
    "    tokens = list(filter(lambda token: token not in eng_stopwords, tokens))\n",
    "    # Lemmatize all tokens:\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tweet:\n",
      " @SouthwestAir good thing we noticed because she had re-routed 7 total passengers on an impossible triple connection as well\n",
      "\n",
      "Tokenized tweet:\n",
      " good thing noticed routed total passenger impossible triple connection well\n"
     ]
    }
   ],
   "source": [
    "tweet = df.Tweet[0]\n",
    "print('Original tweet:\\n',tweet)\n",
    "print('\\nTokenized tweet:\\n',my_tokenizer(tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>@SouthwestAir good thing we noticed because sh...</td>\n",
       "      <td>good thing noticed routed total passenger impo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@united They let us know in advance of the reb...</td>\n",
       "      <td>let u know advance reboot yes thanks attentive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>@USAirways sucks. Delayed my mom's flight 2X, ...</td>\n",
       "      <td>suck delayed mom x cancelled flightled delayed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>@united can you DM me? Been on hold with custo...</td>\n",
       "      <td>dm hold customer service long time min getting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>@AmericanAir THANK YOU FOR ALL THE HELP!  :P Y...</td>\n",
       "      <td>thank help p guy best americanairlines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13874</th>\n",
       "      <td>0</td>\n",
       "      <td>@JetBlue with 3 kids and 11 days 340 + doesn't...</td>\n",
       "      <td>kid day work month advance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13875</th>\n",
       "      <td>1</td>\n",
       "      <td>@AmericanAir LTALJX, from DCA to OMA this morn...</td>\n",
       "      <td>ltaljx dca oma morning staff helped fix proble...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13876</th>\n",
       "      <td>-1</td>\n",
       "      <td>@AmericanAir I can't work with them if the cal...</td>\n",
       "      <td>work call get cut still holding dfw looking be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13877</th>\n",
       "      <td>-1</td>\n",
       "      <td>@AmericanAir 2 months and still no exec platin...</td>\n",
       "      <td>month still exec platinum member card give</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13878</th>\n",
       "      <td>-1</td>\n",
       "      <td>@united quality work going on here. http://t.c...</td>\n",
       "      <td>quality work going http co xbo dakak</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13879 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sentiment                                              Tweet   \n",
       "0             -1  @SouthwestAir good thing we noticed because sh...  \\\n",
       "1              1  @united They let us know in advance of the reb...   \n",
       "2             -1  @USAirways sucks. Delayed my mom's flight 2X, ...   \n",
       "3             -1  @united can you DM me? Been on hold with custo...   \n",
       "4              1  @AmericanAir THANK YOU FOR ALL THE HELP!  :P Y...   \n",
       "...          ...                                                ...   \n",
       "13874          0  @JetBlue with 3 kids and 11 days 340 + doesn't...   \n",
       "13875          1  @AmericanAir LTALJX, from DCA to OMA this morn...   \n",
       "13876         -1  @AmericanAir I can't work with them if the cal...   \n",
       "13877         -1  @AmericanAir 2 months and still no exec platin...   \n",
       "13878         -1  @united quality work going on here. http://t.c...   \n",
       "\n",
       "                                                  Tokens  \n",
       "0      good thing noticed routed total passenger impo...  \n",
       "1      let u know advance reboot yes thanks attentive...  \n",
       "2      suck delayed mom x cancelled flightled delayed...  \n",
       "3      dm hold customer service long time min getting...  \n",
       "4                 thank help p guy best americanairlines  \n",
       "...                                                  ...  \n",
       "13874                         kid day work month advance  \n",
       "13875  ltaljx dca oma morning staff helped fix proble...  \n",
       "13876  work call get cut still holding dfw looking be...  \n",
       "13877         month still exec platinum member card give  \n",
       "13878               quality work going http co xbo dakak  \n",
       "\n",
       "[13879 rows x 3 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Tokens'] = df.apply(lambda x: my_tokenizer(x['Tweet']), axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a collection of text documents to a matrix of binary token counts.\n",
    "vectorizer_bernoulli = CountVectorizer(binary=True)\n",
    "matrix_bernoulli = vectorizer_bernoulli.fit_transform(df['Tokens']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13879, 12120)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_bernoulli.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9993227237198826"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(matrix_bernoulli == 0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix_bernoulli.max()=1\n"
     ]
    }
   ],
   "source": [
    "print(f'{matrix_bernoulli.max()=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_bern_train, x_bern_test, y_train, y_test \\\n",
    "    = train_test_split(matrix_bernoulli, df['Sentiment'].values, \n",
    "                       test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_bernoulli.score(x_bern_test, y_test)=0.7647694524495677\n"
     ]
    }
   ],
   "source": [
    "nb_bernoulli = MultinomialNB()\n",
    "nb_bernoulli.fit(x_bern_train, y_train)\n",
    "print(f'{nb_bernoulli.score(x_bern_test, y_test)=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.29553167e-01, 1.93807730e-01, 1.76639102e-01],\n",
       "       [9.87113597e-01, 1.27997486e-02, 8.66543579e-05],\n",
       "       [9.97510297e-01, 2.12077302e-04, 2.27762606e-03],\n",
       "       ...,\n",
       "       [6.13700421e-01, 3.37121982e-01, 4.91775961e-02],\n",
       "       [9.99997238e-01, 2.50369307e-06, 2.57857408e-07],\n",
       "       [9.99827873e-01, 2.26235770e-05, 1.49503391e-04]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bern_proba = nb_bernoulli.predict_proba(x_bern_test)\n",
    "bern_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_loss(y_test, bern_proba)=0.7119646183926341\n"
     ]
    }
   ],
   "source": [
    "bern_proba /= bern_proba.sum(axis=1)[..., np.newaxis]\n",
    "print(f'{log_loss(y_test, bern_proba)=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['Sentiment'].values\n",
    "\n",
    "nb_bernoulli = MultinomialNB()\n",
    "nb_bernoulli.fit(matrix_bernoulli, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/vectorizer_bernoulli.joblib']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(nb_bernoulli, 'models/nb_bernoulli.joblib')\n",
    "dump(vectorizer_bernoulli, 'models/vectorizer_bernoulli.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msia_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
